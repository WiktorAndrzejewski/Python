{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21af090d",
   "metadata": {},
   "source": [
    "# PYTHON PROJECT: STOCK PRICE PREDICTION USING LSTM \n",
    "\n",
    "## *This project demonstrates how to use Long Short-Term Memory (LSTM) neural networks to predict stock prices. The model predicts the next 7 days of stock prices for a given stock symbol. This project uses historical stock data from Yahoo Finance and is built using Python, TensorFlow, Keras, and Pandas.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8360e91",
   "metadata": {},
   "source": [
    "## 1. Import all the libraries needed\n",
    "\n",
    "This part of the code imports various libraries and modules necessary for the stock price prediction project. Here's a breakdown of the imports:\n",
    "\n",
    "1. `import numpy as np`: Imports the NumPy library, which is used for numerical operations on arrays and matrices.\n",
    "\n",
    "2. `import pandas as pd`: Imports the pandas library, which is used for data manipulation and analysis.\n",
    "\n",
    "3. `from datetime import datetime`: Imports the `datetime` class from the `datetime` module, which is used to handle dates and times.\n",
    "\n",
    "4. `import yfinance as yf`: Imports the yfinance library, which is used to download financial data from Yahoo Finance.\n",
    "\n",
    "5. `from sklearn.preprocessing import MinMaxScaler`: Imports the `MinMaxScaler` class from the scikit-learn library, which is used to scale the data between a specified range (e.g., 0 to 1).\n",
    "\n",
    "6. `from sklearn.metrics import mean_squared_error`: Imports the mean_squared_error function from the scikit-learn library, which is used to calculate the mean squared error between the actual and predicted stock prices.\n",
    "\n",
    "7. `from sklearn.model_selection import TimeSeriesSplit`: Imports the `TimeSeriesSplit` class from the scikit-learn library, which is used for time series cross-validation.\n",
    "\n",
    "8. `from tensorflow.keras.models import Sequential`: Imports the Sequential class from the TensorFlow library, which is used to create a linear stack of layers for the neural network model.\n",
    "\n",
    "9. `from tensorflow.keras.layers import Dense, LSTM, Dropout`: Imports the `Dense`, `LSTM`, and `Dropout` classes from the TensorFlow library, which are used to create the layers of the neural network model.\n",
    "\n",
    "10. `from tensorflow.keras.optimizers import SGD, Adam`: Imports the `SGD` and `Adam` classes from the TensorFlow library, which are used as optimizers for the neural network model.\n",
    "\n",
    "11. `from tensorflow.random import set_seed`: Imports the `set_seed` function from the TensorFlow library, which is used to set the random seed for reproducibility.\n",
    "\n",
    "12. `from keras_tuner import RandomSearch`: Imports the `RandomSearch` class from the Keras Tuner library, which is used to perform random search for hyperparameter tuning.\n",
    "\n",
    "13. `from pandas_datareader.data import DataReader`: Imports the `DataReader` function from the pandas-datareader library, which is used to fetch financial data from various sources, such as Yahoo Finance and Google Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0ffd206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "from keras_tuner import RandomSearch\n",
    "\n",
    "from pandas_datareader.data import DataReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f0700b",
   "metadata": {},
   "source": [
    "### 2. Download historical dataset with financial data about the stock prices using Yahoo Finance API \n",
    "\n",
    "1. `end = datetime.now()`: This line assigns the current date and time to the variable end. The `datetime.now()` function returns the present date and time as a datetime object.\n",
    "\n",
    "2. `start = datetime(2016, end.month, end.day)`: This line creates a datetime object representing the start date for downloading the stock data. The year is set to 2016, while the month and day are set to the current month and day (retrieved from the end variable). This means the start date will be the same day and month as today, but in the year 2016.\n",
    "\n",
    "3. `dataset = yf.download(\"AAPL\", start, end)`: This line downloads the historical stock data for Apple Inc. (AAPL) between the start and end dates using the yfinance library. The downloaded data is stored in a DataFrame named dataset.\n",
    "\n",
    "4. `tstart = 2016` and `tend = 2020`: These lines define two variables, tstart and tend, representing the years for splitting the dataset into a training set and a test set. The training set will contain data from 2016 to 2020, while the test set will contain data from 2021 onwards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aea37fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "end = datetime.now()\n",
    "start = datetime(2016, end.month, end.day) \n",
    "dataset = yf.download(\"AAPL\", start, end) #You can input any stock symbol of your choice for analysis, for example, use \"MSFT\" for Microsoft stocks.\n",
    "tstart = 2016\n",
    "tend = 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac96957",
   "metadata": {},
   "source": [
    "### 3. Preprocess the data by splitting it into training and testing sets, scaling the data, and creating sequences for the LSTM model.\n",
    "\n",
    "This part of the code is responsible for preparing the dataset for training and testing the model. Here's a step-by-step explanation of the code:\n",
    "\n",
    "1. `train_test_plot(dataset, tstart, tend)`: This function takes in the dataset, a start year, and an end year, and plots the training and test data. The training data is plotted between the start and end years, while the test data is plotted from the end year onwards.\n",
    "\n",
    "2. `train_test_split(dataset, tstart, tend)`: This function splits the dataset into training and test sets based on the given start and end years. The training set includes data between the start and end years, while the test set includes data from the end year onwards.\n",
    "\n",
    "3. `train_test_split_values(dataset, tstart, tend)`: This function calls `train_test_split()` to get the training and test sets, and then returns their values as numpy arrays.\n",
    "\n",
    "4. `training_set, test_set = train_test_split_values(dataset, tstart, tend)`: This line of code calls the `train_test_split_values()` function to obtain the training and test sets.\n",
    "\n",
    "5. The MinMaxScaler is initialized with a feature range of (0, 1). The training set is then reshaped and scaled using this scaler. This scaling is done to ensure that all the values are between 0 and 1, which helps improve the performance of the neural network.\n",
    "\n",
    "6. `split_sequence(sequence, window)`: This function takes a sequence of data and a window size as input, and creates input-output pairs for the sequence. The input is a sliding window of data, while the output is the next value in the sequence after the window.\n",
    "\n",
    "7. `window_size` and `features`: These variables define the window size (60) and the number of features (1) for the input data.\n",
    "\n",
    "8. `X_train, y_train = split_sequence(training_set_scaled, window_size)`: This line of code calls the split_sequence() function to create the input-output pairs for the training data.\n",
    "\n",
    "9. `X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],features)`: This line reshapes the input training data (X_train) to the required 3-dimensional format for the LSTM model. The dimensions are (number of samples, time steps, number of features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "443cc44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_plot(dataset, tstart, tend):\n",
    "    dataset.loc[f\"{tstart}\":f\"{tend}\", \"High\"].plot(figsize=(16, 4), legend=True)\n",
    "    dataset.loc[f\"{tend+1}\":, \"High\"].plot(figsize=(16, 4), legend=True)\n",
    "    \n",
    "\n",
    "def train_test_split(dataset, tstart, tend):\n",
    "    train = dataset.loc[f\"{tstart}\":f\"{tend}\", \"High\"]\n",
    "    test = dataset.loc[f\"{tend+1}\":, \"High\"]\n",
    "    return train, test\n",
    "\n",
    "def train_test_split_values(dataset, tstart, tend):\n",
    "    train, test =  train_test_split(dataset, tstart, tend)\n",
    "    return train.values, test.values\n",
    "\n",
    "training_set, test_set = train_test_split_values(dataset, tstart, tend)\n",
    "\n",
    "\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "training_set = training_set.reshape(-1, 1)\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "def split_sequence(sequence, window):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + window\n",
    "        if end_ix > len(sequence) - 1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 60\n",
    "features = 1\n",
    "\n",
    "X_train, y_train = split_sequence(training_set_scaled, window_size)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b58457",
   "metadata": {},
   "source": [
    "### 4. Define the LSTM model, compile it, and fit it on the training data.\n",
    "\n",
    "1. `model_lstm = Sequential()`: This line creates a sequential model, which is a linear stack of layers that can be built up one layer at a time.\n",
    "\n",
    "2. The next few lines define the structure of the LSTM model:\n",
    "\n",
    "- The first LSTM layer has 128 units, a \"tanh\" activation function, an input shape of (window_size, features), and return_sequences=True, which means it will return the full sequence of hidden states for each time step.\n",
    "- A Dropout layer is added with a dropout rate of 0.2 to prevent overfitting.\n",
    "- The second LSTM layer has 64 units and a \"tanh\" activation function.\n",
    "- Another Dropout layer is added with a dropout rate of 0.1.\n",
    "- A Dense layer with a single output unit is added to produce the predicted stock price.\n",
    "3. `model_lstm.compile(optimizer=Adam(learning_rate=0.01), loss='mse')`: This line compiles the model with the Adam optimizer, a learning rate of 0.01, and mean squared error (mse) as the loss function.\n",
    "\n",
    "4. `model_lstm.summary()` and `print(model_lstm)`: These lines print a summary of the model architecture.\n",
    "\n",
    "5. `model_lstm.fit(X_train, y_train, epochs=30, batch_size=32)`: This line trains the LSTM model on the training data (X_train and y_train) for 30 epochs with a batch size of 32.\n",
    "\n",
    "6. `dataset_total = dataset.loc[:,\"High\"]`: This line extracts the \"High\" price column from the dataset.\n",
    "\n",
    "7. `inputs = dataset_total[len(dataset_total) - len(test_set) - window_size :].values`: This line creates an input array for the test set by taking the last `window_size` number of values from the dataset, combined with the test set values.\n",
    "\n",
    "8. The next few lines reshape and scale the inputs using the MinMaxScaler (sc) that was previously fit on the training data.\n",
    "\n",
    "9. `X_test, y_test = split_sequence(inputs, window_size)`: This line calls the split_sequence() function to create input-output pairs for the test data.\n",
    "\n",
    "10. `X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], features)`: This line reshapes the input test data (X_test) to the required 3-dimensional format for the LSTM model.\n",
    "\n",
    "11. `predicted_stock_price = model_lstm.predict(X_test)`: This line makes predictions on the test data using the trained LSTM model.\n",
    "\n",
    "12. The next two lines inverse transform the predicted_stock_price and y_test using the MinMaxScaler (`sc`). This step converts the scaled values back to their original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14acd11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 60, 128)           66560     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 60, 128)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 116,033\n",
      "Trainable params: 116,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "<keras.engine.sequential.Sequential object at 0x000002282E431430>\n",
      "Epoch 1/30\n",
      "35/35 [==============================] - 4s 37ms/step - loss: 0.0477\n",
      "Epoch 2/30\n",
      "35/35 [==============================] - 1s 38ms/step - loss: 0.0023\n",
      "Epoch 3/30\n",
      "35/35 [==============================] - 1s 38ms/step - loss: 0.0012\n",
      "Epoch 4/30\n",
      "35/35 [==============================] - 1s 36ms/step - loss: 0.0013\n",
      "Epoch 5/30\n",
      "35/35 [==============================] - 1s 38ms/step - loss: 0.0014\n",
      "Epoch 6/30\n",
      "35/35 [==============================] - 1s 42ms/step - loss: 0.0011\n",
      "Epoch 7/30\n",
      "35/35 [==============================] - 1s 40ms/step - loss: 8.5377e-04\n",
      "Epoch 8/30\n",
      "35/35 [==============================] - 1s 39ms/step - loss: 9.8194e-04\n",
      "Epoch 9/30\n",
      "35/35 [==============================] - 1s 43ms/step - loss: 8.8450e-04\n",
      "Epoch 10/30\n",
      "35/35 [==============================] - 1s 42ms/step - loss: 8.1642e-04\n",
      "Epoch 11/30\n",
      "35/35 [==============================] - 1s 40ms/step - loss: 7.2834e-04\n",
      "Epoch 12/30\n",
      "35/35 [==============================] - 1s 41ms/step - loss: 8.4451e-04\n",
      "Epoch 13/30\n",
      "35/35 [==============================] - 1s 39ms/step - loss: 8.3366e-04\n",
      "Epoch 14/30\n",
      "35/35 [==============================] - 1s 41ms/step - loss: 9.0454e-04\n",
      "Epoch 15/30\n",
      "35/35 [==============================] - 1s 39ms/step - loss: 7.9964e-04\n",
      "Epoch 16/30\n",
      "35/35 [==============================] - 1s 41ms/step - loss: 8.3354e-04\n",
      "Epoch 17/30\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 7.3813e-04\n",
      "Epoch 18/30\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 8.4625e-04\n",
      "Epoch 19/30\n",
      "35/35 [==============================] - 2s 50ms/step - loss: 8.1667e-04\n",
      "Epoch 20/30\n",
      "35/35 [==============================] - 1s 42ms/step - loss: 7.4134e-04\n",
      "Epoch 21/30\n",
      "35/35 [==============================] - 1s 40ms/step - loss: 9.9204e-04\n",
      "Epoch 22/30\n",
      "35/35 [==============================] - 1s 41ms/step - loss: 7.2777e-04\n",
      "Epoch 23/30\n",
      "35/35 [==============================] - 1s 41ms/step - loss: 6.5443e-04\n",
      "Epoch 24/30\n",
      "35/35 [==============================] - 1s 41ms/step - loss: 5.4121e-04\n",
      "Epoch 25/30\n",
      "35/35 [==============================] - 2s 43ms/step - loss: 5.2741e-04\n",
      "Epoch 26/30\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 5.6252e-04\n",
      "Epoch 27/30\n",
      "35/35 [==============================] - 1s 43ms/step - loss: 6.7095e-04\n",
      "Epoch 28/30\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 7.9464e-04\n",
      "Epoch 29/30\n",
      "35/35 [==============================] - 2s 44ms/step - loss: 6.9161e-04\n",
      "Epoch 30/30\n",
      "35/35 [==============================] - 2s 44ms/step - loss: 5.8981e-04\n",
      "19/19 [==============================] - 1s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(units=128, activation=\"tanh\", input_shape=(window_size, features), return_sequences=True))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(LSTM(units=64, activation=\"tanh\"))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(Dense(units=1))\n",
    "\n",
    "model_lstm.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
    "\n",
    "model_lstm.summary()\n",
    "print(model_lstm)\n",
    "\n",
    "model_lstm.fit(X_train, y_train, epochs=30, batch_size=32)\n",
    "\n",
    "dataset_total = dataset.loc[:,\"High\"]\n",
    "inputs = dataset_total[len(dataset_total) - len(test_set) - window_size :].values\n",
    "inputs = inputs.reshape(-1, 1)\n",
    "inputs = sc.transform(inputs)\n",
    "\n",
    "X_test, y_test = split_sequence(inputs, window_size)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], features)\n",
    "predicted_stock_price = model_lstm.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "y_test = sc.inverse_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589db8cf",
   "metadata": {},
   "source": [
    "### 5.Predict stock prices for the test set and calculate the root mean squared error (RMSE).\n",
    "\n",
    "This part of the code defines a function called return_rmse that calculates the Root Mean Squared Error (RMSE) between the actual test data and the predicted data. RMSE is a commonly used metric to evaluate the performance of a regression model, such as a stock price prediction model in this case. Here's a breakdown of the code:\n",
    "\n",
    "1. `def return_rmse(test, predicted)`:: This line defines the `return_rmse` function, which takes two arguments: `test` and `predicted`. `test` refers to the actual test data (y_test), and `predicted` refers to the predicted stock prices from the model (predicted_stock_price).\n",
    "\n",
    "2. `rmse = np.sqrt(mean_squared_error(test, predicted))`: This line calculates the RMSE by first computing the mean squared error (MSE) between the test and predicted data using the `mean_squared_error()` function from the `sklearn.metrics` module. Then, it takes the square root of the MSE using NumPy's `np.sqrt()` function.\n",
    "\n",
    "3. `print(\"The root mean squared error is {:.2f}.\".format(rmse))`: This line prints the RMSE value with a message and formats the floating-point number with two decimal places using the `format()` method.\n",
    "\n",
    "4. `return_rmse(y_test, predicted_stock_price)`: This line calls the `return_rmse` function with `y_test` and `predicted_stock_price` as arguments, which calculates and prints the RMSE for the stock price prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6beab313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean squared error is 6.29.\n"
     ]
    }
   ],
   "source": [
    "def return_rmse(test, predicted):\n",
    "    rmse = np.sqrt(mean_squared_error(test, predicted))\n",
    "    print(\"The root mean squared error is {:.2f}.\".format(rmse))\n",
    "\n",
    "return_rmse(y_test,predicted_stock_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bfd45a",
   "metadata": {},
   "source": [
    "### 6. Predict stock prices for the next 7 days and display the results.\n",
    "\n",
    "This part of the code generates predictions for the stock prices for the next 7 days using the trained LSTM model. Here's a breakdown of the code:\n",
    "\n",
    "1. `future_predictions = []`: This line initializes an empty list called `future_predictions` to store the predicted stock prices for the next 7 days.\n",
    "\n",
    "2. `last_60_days = dataset_total[-window_size:]`.values: This line extracts the last 60 days of stock prices from the dataset, as it will be used as the input for predicting the next day's stock price.\n",
    "\n",
    "3. `last_60_days = last_60_days.reshape(-1, 1)`: This line reshapes the `last_60_days` array to have one column and an appropriate number of rows.\n",
    "\n",
    "4. `last_60_days = sc.transform(last_60_days)`: This line scales the `last_60_days` data using the same MinMaxScaler (`sc`) that was used for the training data.\n",
    "\n",
    "5. `for i in range(7)`:: This line starts a loop that iterates 7 times, as we want to predict stock prices for the next 7 days.\n",
    "\n",
    "6. `input_data = last_60_days[-window_size:].reshape(1, window_size, features)`: This line prepares the input data for the LSTM model by taking the last 60 days of the `last_60_days`array, reshaping it to match the input shape expected by the LSTM model (1, window_size, features).\n",
    "\n",
    "7. `predicted_price = model_lstm.predict(input_data)`: This line makes a prediction for the next day's stock price using the LSTM model.\n",
    "\n",
    "8. `last_60_days = np.concatenate((last_60_days, predicted_price), axis=0)`: This line appends the predicted stock price to the `last_60_days` array, which will be used as input for the next prediction. It also removes the oldest stock price from the array.\n",
    "\n",
    "9. `predicted_price = sc.inverse_transform(predicted_price)`: This line inverse transforms the predicted stock price to its original scale using the MinMaxScaler (`sc`).\n",
    "\n",
    "10. `future_predictions.append(predicted_price[0][0])`: This line adds the predicted stock price to the future_predictions list.\n",
    "\n",
    "11. `print(\"Predicted stock prices for the next 7 days:\")`: This line prints a message to indicate that the predicted stock prices for the next 7 days will be displayed.\n",
    "\n",
    "12. `for i, price in enumerate(future_predictions)`:: This line starts a loop that iterates through the `future_predictions` list.\n",
    "\n",
    "13. `print(f\"Day {i + 1}: {price:.2f}\")`: This line prints the predicted stock price for each day in a formatted string with two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f4a9969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predicted stock prices for the next 7 days:\n",
      "Day 1: 164.65\n",
      "Day 2: 163.06\n",
      "Day 3: 160.94\n",
      "Day 4: 158.53\n",
      "Day 5: 156.06\n",
      "Day 6: 153.74\n",
      "Day 7: 151.58\n"
     ]
    }
   ],
   "source": [
    "future_predictions = []\n",
    "\n",
    "last_60_days = dataset_total[-window_size:].values\n",
    "last_60_days = last_60_days.reshape(-1, 1)\n",
    "last_60_days = sc.transform(last_60_days)\n",
    "\n",
    "for i in range(7):\n",
    "    input_data = last_60_days[-window_size:].reshape(1, window_size, features)\n",
    "    predicted_price = model_lstm.predict(input_data)\n",
    "    last_60_days = np.concatenate((last_60_days, predicted_price), axis=0)\n",
    "    predicted_price = sc.inverse_transform(predicted_price)\n",
    "    future_predictions.append(predicted_price[0][0])\n",
    "\n",
    "print(\"Predicted stock prices for the next 7 days:\")\n",
    "for i, price in enumerate(future_predictions):\n",
    "    print(f\"Day {i + 1}: {price:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c33dda",
   "metadata": {},
   "source": [
    "### 7. Tune the parameters of the model\n",
    "\n",
    "This part of the code defines a function called build_model that takes a hp (hyperparameter) argument and constructs an LSTM model using the Keras library. It also sets up a random search to find the optimal hyperparameters for the model using the Keras Tuner library. Here's a breakdown of the code:\n",
    "\n",
    "1. `def build_model(hp):`: This line defines the build_model function, which accepts a hp argument representing the hyperparameters of the model.\n",
    "\n",
    "2. `model = Sequential()`: This line creates an empty Sequential model.\n",
    "\n",
    "3. The next few lines add two LSTM layers with dropout layers in between:\n",
    "\n",
    "a. `model.add(LSTM(...))`: These lines add LSTM layers with the specified number of units, activation function, and input shape. The number of units is determined by the hyperparameter optimization process, with a range between 32 and 256 and a step of 32.\n",
    "\n",
    "b. `model.add(Dropout(...))`: These lines add dropout layers to the model to prevent overfitting. The dropout rate is also determined by the hyperparameter optimization process, with a range between 0.0 and 0.5 and a step of 0.1.\n",
    "\n",
    "4. `model.add(Dense(units=1))`: This line adds a Dense layer with a single output unit, which represents the predicted stock price.\n",
    "\n",
    "5. `model.compile(...)`: This line compiles the model, specifying the optimizer (Adam), learning rate, and loss function (mean squared error). The learning rate is also determined by the hyperparameter optimization process, with a choice among 0.01, 0.001, and 0.0001.\n",
    "\n",
    "6. `return model`: This line returns the constructed model.\n",
    "\n",
    "7. `tuner = RandomSearch(...`): This line creates a `RandomSearch` object, which searches for the best hyperparameters for the model. It takes the `build_model` function as input, along with the objective (minimizing validation loss), the number of trials, the number of executions per trial, and the directory and project name to store the results.\n",
    "\n",
    "8. `tuner.search_space_summary()`: This line prints a summary of the search space for the hyperparameters.\n",
    "\n",
    "9. `tuner.search(...)`: This line runs the random search for the best hyperparameters, training the model with the specified number of epochs, batch size, validation split, and verbosity level.\n",
    "\n",
    "10. `tuner.results_summary()`: This line prints a summary of the best hyperparameters found during the search.\n",
    "\n",
    "11. `best_model = tuner.get_best_models(num_models=1)[0]`: This line retrieves the best model found during the search and assigns it to the `best_model` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(units=hp.Int('units_1', min_value=32, max_value=256, step=32),\n",
    "                   activation='tanh',\n",
    "                   input_shape=(window_size, features),\n",
    "                   return_sequences=True))\n",
    "    \n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(LSTM(units=hp.Int('units_2', min_value=32, max_value=256, step=32),\n",
    "                   activation='tanh'))\n",
    "    \n",
    "    model.add(Dropout(hp.Float('dropout_2', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    model.compile(optimizer=Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "                  loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=30,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='stock_prediction')\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=50,\n",
    "             batch_size=32,\n",
    "             validation_split=0.2,\n",
    "             verbose=1)\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
